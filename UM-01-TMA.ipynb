{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, dataset='hillstrom', verbose=True):\n",
    "    # For Hillstrom dataset, the ‘‘visit’’ target variable was selected\n",
    "    #   as the target variable of interest and the selected treatment is \n",
    "    #   the e-mail campaign for women’s merchandise [1]\n",
    "    # [1] Kane K, Lo VSY, Zheng J. True-lift modeling: Comparison of methods. \n",
    "    #    J Market Anal. 2014;2:218–238\n",
    "    dataset = dataset.lower()\n",
    "    if dataset in ('hillstrom', 'email'):\n",
    "        columns = df.columns\n",
    "        for col in columns:\n",
    "            if df[col].dtype != object:\n",
    "                continue\n",
    "            df = pd.concat(\n",
    "                    [df, pd.get_dummies(df[col], \n",
    "                                        prefix=col, \n",
    "                                        drop_first=False)],\n",
    "                    axis=1)\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "\n",
    "        df.columns = [col.replace('-', '').replace(' ', '_').lower()\n",
    "                      for col in df.columns]\n",
    "        df = df[df.segment_mens_email == 0]\n",
    "        df.index = range(len(df))\n",
    "        df.drop(['segment_mens_email', \n",
    "                 'segment_no_email', \n",
    "                 'conversion', \n",
    "                 'spend'], axis=1, inplace=True)\n",
    "\n",
    "        y_name = 'visit'\n",
    "        t_name = 'segment_womens_email'\n",
    "    elif dataset in ['criteo', 'ad']:\n",
    "        df = df.fillna(0)\n",
    "        y_name = 'y'\n",
    "        t_name = 'treatment'\n",
    "    elif dataset == 'lalonde':\n",
    "        y_name = 'RE78'\n",
    "        t_name = 'treatment'\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    df['Y'] = df[y_name]\n",
    "    df.drop([y_name], axis=1, inplace=True)\n",
    "    df['T'] = df[t_name]\n",
    "    df.drop([t_name], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ty_assign(y, t):\n",
    "    if y == 1 and t == 1:\n",
    "        return \"TR\"\n",
    "    elif y == 0 and t == 1:\n",
    "        return \"TN\"\n",
    "    elif y == 1 and t == 0:\n",
    "        return \"CR\"\n",
    "    elif y == 0 and t == 0:\n",
    "        return \"CN\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def t_assign(ty):\n",
    "    if ty in (\"TR\", \"TN\"):\n",
    "        return 1\n",
    "    elif ty in (\"CR\", \"CN\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def y_assign(ty):\n",
    "    if ty in (\"TR\", \"CR\"):\n",
    "        return 1\n",
    "    elif ty in (\"TN\", \"CN\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tma(x, y, t, method=LogisticRegression, **kwargs):\n",
    "    \"\"\"Training a model according to the \"Two Model Approach\" \n",
    "    (a.k.a. \"Separate Model Approach\")\n",
    "    The default model is General Linear Model (GLM)\n",
    "    \n",
    "    Source: \"Incremental Value Modeling\" (Hansotia, 2002)\n",
    "\n",
    "    Args:\n",
    "        x: A data frame of predictors.\n",
    "        y: A binary response (numeric) vector.\n",
    "        t: A binary response (numeric) representing the treatment assignment\n",
    "            (coded as 0/1).\n",
    "        method: A sklearn model specifying which classification or regression\n",
    "            model to use. This should be a method that can handle a \n",
    "            multinominal class variable.\n",
    "\n",
    "    Return:\n",
    "        Dictionary: A dictionary of two models. One for the treatment group, \n",
    "            one for the control group.\n",
    "\n",
    "            {\n",
    "                'model_treat': a model for the treatment group,\n",
    "                'model_control': a model for the control group\n",
    "            }\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    treat_rows = (t == 1)\n",
    "    control_rows = (t == 0)\n",
    "    model_treat = method(**kwargs).fit(x[treat_rows], y[treat_rows])\n",
    "    model_control = method(**kwargs).fit(x[control_rows], y[control_rows])\n",
    "    \n",
    "    res = {\n",
    "        'model_treat': model_treat,\n",
    "        'model_control': model_control,\n",
    "    }\n",
    "    return res\n",
    "\n",
    "\n",
    "def predict_tma(obj, newdata, **kwargs):\n",
    "    \"\"\"Predictions according to the \"Two Model Approach\" \n",
    "    (a.k.a. \"Separate Model Approach\")\n",
    "    \n",
    "    For each instance in newdata two predictions are made:\n",
    "    1) What is the probability of a person responding when treated?\n",
    "    2) What is the probability of a person responding when not treated\n",
    "      (i.e. part of control group)?\n",
    "\n",
    "    Source: \"Incremental Value Modeling\" (Hansotia, 2002)\n",
    "\n",
    "    Args:\n",
    "        obj: A dictionary of two models. \n",
    "            One for the treatment group, one for the control group.\n",
    "        newdata: A data frame containing the values at which predictions\n",
    "            are required.\n",
    "    \n",
    "    Return:\n",
    "        DataFrame: A dataframe with predicted returns for when the customers\n",
    "            are treated and for when they are not treated.\n",
    "    \"\"\"\n",
    "   \n",
    "    if isinstance(obj['model_treat'], LinearRegression):\n",
    "        pred_treat = obj['model_treat'].predict(newdata)\n",
    "    else:\n",
    "        pred_treat = obj['model_treat'].predict_proba(newdata)[:, 1]\n",
    "\n",
    "    if isinstance(obj['model_control'], LinearRegression):\n",
    "        pred_control = obj['model_control'].predict(newdata)\n",
    "    else:\n",
    "        pred_control = obj['model_control'].predict_proba(newdata)[:, 1]\n",
    "    \n",
    "    # pred_treat = obj['model_treat'].predict(newdata)\n",
    "    # pred_control = obj['model_control'].predict(newdata)\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"pr_y1_t1\": pred_treat,\n",
    "        \"pr_y1_t0\": pred_control,\n",
    "    })\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def performance(pr_y1_t1, pr_y1_t0, y, t, groups=10):\n",
    "    \"\"\"\n",
    "    1. Split the total customers into the given number of groups\n",
    "    2. Calculate the statistics of each segment\n",
    "    \n",
    "    Args:\n",
    "        pr_y1_t1: the series (list) of the customer's expected return\n",
    "        pr_y1_t0: the expected return when a customer is not treated\n",
    "        y: the observed return of customers\n",
    "        t: whther each customer is treated or not\n",
    "        groups: the number of groups (segments). Should be 5, 10, or 20\n",
    "    Return:\n",
    "        DataFrame:\n",
    "            columns:\n",
    "                'n_y1_t1': the number of treated responders\n",
    "                'n_y1_t0': the number of not treated responders\n",
    "                'r_y1_t1': the average return of treated customers\n",
    "                'r_y1_t0': the average return of not treated customers\n",
    "                'n_t1': the number of treated customers\n",
    "                'n_t0': the number of not treated customers\n",
    "                'uplift': the average uplift (the average treatment effect)\n",
    "            rows: the index of groups\n",
    "    \"\"\"\n",
    "  \n",
    "    ### check valid arguments\n",
    "    if groups not in [5, 10, 20]:\n",
    "        raise Exception(\"uplift: groups must be either 5, 10 or 20\")\n",
    "  \n",
    "    ### check for NAs.\n",
    "    if pr_y1_t1.isnull().values.any():\n",
    "        raise Exception(\"uplift: NA not permitted in pr_y1_t1\")\n",
    "    if pr_y1_t0.isnull().values.any():\n",
    "        raise Exception(\"uplift: NA not permitted in pr_y1_t0\")\n",
    "    if y.isnull().values.any():\n",
    "        raise Exception(\"uplift: NA not permitted in y\")\n",
    "    if t.isnull().values.any():\n",
    "        raise Exception(\"uplift: NA not permitted in t\")\n",
    "   \n",
    "    ### check valid values for y and t\n",
    "    # if set(y) != {0, 1}:\n",
    "    #     raise Exception(\"uplift: y must be either 0 or 1\")\n",
    "    if set(t) != {0, 1}:\n",
    "        raise Exception(\"uplift: t must be either 0 or 1\")\n",
    "\n",
    "    ### check length of arguments\n",
    "    if not (len(pr_y1_t1) == len(pr_y1_t0) == len(y) == len(t)):\n",
    "        raise Exception(\"uplift: arguments pr_y1_t1, pr_y1_t0, y and t must all have the same length\")\n",
    "\n",
    "    ### define dif_pred\n",
    "    dif_pred = pr_y1_t1 - pr_y1_t0\n",
    "  \n",
    "    ### Make index same\n",
    "    y.index = dif_pred.index\n",
    "    t.index = dif_pred.index\n",
    "    \n",
    "    mm = pd.DataFrame({\n",
    "        'dif_pred': dif_pred,\n",
    "        'y': y,\n",
    "        't': t,\n",
    "        'dif_pred_r': dif_pred.rank(ascending=False, method='first')\n",
    "    })\n",
    "\n",
    "    mm_groupby = mm.groupby(pd.qcut(mm['dif_pred_r'], groups, labels=range(1, groups+1), duplicates='drop'))\n",
    "  \n",
    "    n_y1_t1 = mm_groupby.apply(lambda r: r[r['t'] == 1]['y'].sum())\n",
    "    n_y1_t0 = mm_groupby.apply(lambda r: r[r['t'] == 0]['y'].sum())\n",
    "    n_t1 = mm_groupby['t'].sum()\n",
    "    n_t0 = mm_groupby['t'].count() - n_t1\n",
    "  \n",
    "    df = pd.DataFrame({\n",
    "        'n_t1': n_t1,\n",
    "        'n_t0': n_t0,\n",
    "        'n_y1_t1': n_y1_t1,\n",
    "        'n_y1_t0': n_y1_t0,\n",
    "        'r_y1_t1': n_y1_t1 / n_t1,\n",
    "        'r_y1_t0': n_y1_t0 / n_t0,\n",
    "    })\n",
    "    fillna_columns = ['n_y1_t1', 'n_y1_t0', 'n_t1', 'n_t0']\n",
    "    df[fillna_columns] = df[fillna_columns].fillna(0)\n",
    "    df.index.name = 'groups'\n",
    "\n",
    "    df['uplift'] = df['r_y1_t1'] - df['r_y1_t0']\n",
    "    df['uplift'] = round(df['uplift'], 6)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def qini(perf, plotit=True):\n",
    "    nrow = len(perf)\n",
    "\n",
    "    # Calculating the incremental gains. \n",
    "    # - First, the cumulitative sum of the treated and the control groups are\n",
    "    #  calculated with respect to the total population in each group at the\n",
    "    #  specified decile\n",
    "    # - Afterwards we calculate the percentage of the total amount of people\n",
    "    #  (both treatment and control) are present in each decile\n",
    "    cumul_y1_t1 = (perf['n_y1_t1'].cumsum() / perf['n_t1'].cumsum()).fillna(0)\n",
    "    cumul_y1_t0 = (perf['n_y1_t0'].cumsum() / perf['n_t0'].cumsum()).fillna(0)\n",
    "    deciles = [i/nrow for i in range(1, nrow+1)]\n",
    "\n",
    "    ### Model Incremental gains\n",
    "    inc_gains = (cumul_y1_t1 - cumul_y1_t0) * deciles\n",
    "    inc_gains = [0.0] + list(inc_gains)\n",
    "\n",
    "    ### Overall incremental gains\n",
    "    overall_inc_gain = sum(perf['n_y1_t1']) / sum(perf['n_t1']) \\\n",
    "            - sum(perf['n_y1_t0']) / sum(perf['n_t0'])\n",
    "\n",
    "    ### Random incremental gains\n",
    "    random_inc_gains = [i*overall_inc_gain / nrow for i in range(nrow+1)]\n",
    "\n",
    "    ### Compute area under the model incremental gains (uplift) curve\n",
    "    x = [0] + deciles\n",
    "    y = list(inc_gains)\n",
    "    auuc = 0\n",
    "    auuc_rand = 0\n",
    "\n",
    "    auuc_list = [auuc]\n",
    "    for i in range(1, len(x)):\n",
    "        auuc += 0.5 * (x[i] - x[i-1]) * (y[i] + y[i-1])\n",
    "        auuc_list.append(auuc)\n",
    "\n",
    "    ### Compute area under the random incremental gains curve\n",
    "    y_rand = random_inc_gains\n",
    "\n",
    "    auuc_rand_list = [auuc_rand]\n",
    "    for i in range(1, len(x)):\n",
    "        auuc_rand += 0.5 * (x[i] - x[i-1]) * (y_rand[i] + y_rand[i-1])\n",
    "        auuc_rand_list.append(auuc_rand)\n",
    "\n",
    "    ### Compute the difference between the areas (Qini coefficient)\n",
    "    Qini = auuc - auuc_rand\n",
    "\n",
    "    ### Plot incremental gains curve\n",
    "    if plotit:\n",
    "        x_axis = x\n",
    "        plt.plot(x_axis, inc_gains)\n",
    "        plt.plot(x_axis, random_inc_gains)\n",
    "        plt.show()\n",
    "    \n",
    "    ### Qini 30%, Qini 10%\n",
    "    n_30p = int(nrow*3/10)\n",
    "    n_10p = int(nrow/10)\n",
    "    qini_30p = auuc_list[n_30p] - auuc_rand_list[n_30p]\n",
    "    qini_10p = auuc_list[n_10p] - auuc_rand_list[n_10p]\n",
    "\n",
    "    res = {\n",
    "        'qini': Qini,\n",
    "        'inc_gains': inc_gains,\n",
    "        'random_inc_gains': random_inc_gains,\n",
    "        'auuc_list': auuc_list,\n",
    "        'auuc_rand_list': auuc_rand_list,\n",
    "        'qini_30p': qini_30p,\n",
    "        'qini_10p': qini_10p,\n",
    "    }    \n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCase = 1\n",
    "\n",
    "if(TestCase==1):\n",
    "    df = pd.read_csv('Hillstrom.csv')\n",
    "    dataset = 'hillstrom'\n",
    "elif(TestCase==2):\n",
    "    df = pd.read_csv('criteo_small.csv')\n",
    "    dataset = 'criteo'\n",
    "else:\n",
    "    df = pd.read_csv('Lalonde.csv')\n",
    "    dataset = 'lalonde'\n",
    "\n",
    "\n",
    "df = preprocess_data(df, dataset=dataset)\n",
    "Y = df['Y']\n",
    "T = df['T']\n",
    "X = df.drop(['Y', 'T'], axis=1)\n",
    "if(dataset != 'lalonde'):\n",
    "    ty = pd.DataFrame({'Y': Y, 'T': T}).apply(lambda row: ty_assign(row['Y'], row['T']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'hillstrom':\n",
    "    fold_gen = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234).split(X, ty)\n",
    "elif dataset == 'criteo':\n",
    "    fold_gen = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234).split(X, ty)\n",
    "elif dataset == 'lalonde':\n",
    "    fold_gen = KFold(n_splits=5, shuffle=True, random_state=1234).split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42693"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, (train_index, test_index) in enumerate(fold_gen):\n",
    "    train_index = train_index\n",
    "    test_index = test_index\n",
    "    \n",
    "X_train = X.reindex(train_index)\n",
    "X_test = X.reindex(test_index)\n",
    "if (dataset != 'lalonde'):\n",
    "    Y = ty.apply(y_assign)\n",
    "    T = ty.apply(t_assign)\n",
    "Y_train = Y.reindex(train_index)\n",
    "Y_test = Y.reindex(test_index)\n",
    "T_train = T.reindex(train_index)\n",
    "T_test = T.reindex(test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = tma(X_train, Y_train, T_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_treat': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'model_control': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_tma(mdl, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = performance(pred['pr_y1_t1'], pred['pr_y1_t0'], Y_test, T_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_t1</th>\n",
       "      <th>n_t0</th>\n",
       "      <th>n_y1_t1</th>\n",
       "      <th>n_y1_t0</th>\n",
       "      <th>r_y1_t1</th>\n",
       "      <th>r_y1_t0</th>\n",
       "      <th>uplift</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groups</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>420</td>\n",
       "      <td>434</td>\n",
       "      <td>94</td>\n",
       "      <td>66</td>\n",
       "      <td>0.223810</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>0.071736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>438</td>\n",
       "      <td>416</td>\n",
       "      <td>75</td>\n",
       "      <td>54</td>\n",
       "      <td>0.171233</td>\n",
       "      <td>0.129808</td>\n",
       "      <td>0.041425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>433</td>\n",
       "      <td>420</td>\n",
       "      <td>82</td>\n",
       "      <td>49</td>\n",
       "      <td>0.189376</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.072710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>448</td>\n",
       "      <td>406</td>\n",
       "      <td>78</td>\n",
       "      <td>41</td>\n",
       "      <td>0.174107</td>\n",
       "      <td>0.100985</td>\n",
       "      <td>0.073122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>414</td>\n",
       "      <td>439</td>\n",
       "      <td>66</td>\n",
       "      <td>44</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.100228</td>\n",
       "      <td>0.059192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>422</td>\n",
       "      <td>432</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>0.071759</td>\n",
       "      <td>0.039615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>424</td>\n",
       "      <td>429</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>0.067599</td>\n",
       "      <td>0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>423</td>\n",
       "      <td>431</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>0.130024</td>\n",
       "      <td>0.092807</td>\n",
       "      <td>0.037216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>435</td>\n",
       "      <td>418</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>0.128736</td>\n",
       "      <td>0.086124</td>\n",
       "      <td>0.042611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>419</td>\n",
       "      <td>435</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>0.152745</td>\n",
       "      <td>0.142529</td>\n",
       "      <td>0.010216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_t1  n_t0  n_y1_t1  n_y1_t0   r_y1_t1   r_y1_t0    uplift\n",
       "groups                                                            \n",
       "1        420   434       94       66  0.223810  0.152074  0.071736\n",
       "2        438   416       75       54  0.171233  0.129808  0.041425\n",
       "3        433   420       82       49  0.189376  0.116667  0.072710\n",
       "4        448   406       78       41  0.174107  0.100985  0.073122\n",
       "5        414   439       66       44  0.159420  0.100228  0.059192\n",
       "6        422   432       47       31  0.111374  0.071759  0.039615\n",
       "7        424   429       30       29  0.070755  0.067599  0.003156\n",
       "8        423   431       55       40  0.130024  0.092807  0.037216\n",
       "9        435   418       56       36  0.128736  0.086124  0.042611\n",
       "10       419   435       64       62  0.152745  0.142529  0.010216"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = qini(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qini': 0.00470693033901028,\n",
       " 'inc_gains': [0.0,\n",
       "  0.00717357910906298,\n",
       "  0.011158645276292335,\n",
       "  0.01840561854632617,\n",
       "  0.025556343933432247,\n",
       "  0.031685185002179594,\n",
       "  0.03585248207485677,\n",
       "  0.03631252980384142,\n",
       "  0.040079823281287175,\n",
       "  0.04427366590919488,\n",
       "  0.0452063487880824],\n",
       " 'random_inc_gains': [0.0,\n",
       "  0.00452063487880824,\n",
       "  0.00904126975761648,\n",
       "  0.013561904636424722,\n",
       "  0.01808253951523296,\n",
       "  0.0226031743940412,\n",
       "  0.027123809272849443,\n",
       "  0.03164444415165768,\n",
       "  0.03616507903046592,\n",
       "  0.040685713909274154,\n",
       "  0.0452063487880824],\n",
       " 'auuc_list': [0,\n",
       "  0.000358678955453149,\n",
       "  0.0012752901747209147,\n",
       "  0.0027535033658518393,\n",
       "  0.004951601489839761,\n",
       "  0.007813677936620352,\n",
       "  0.01119056129047217,\n",
       "  0.014798811884407079,\n",
       "  0.018618429538663512,\n",
       "  0.022836103998187612,\n",
       "  0.027310104733051475],\n",
       " 'auuc_rand_list': [0,\n",
       "  0.000226031743940412,\n",
       "  0.0009041269757616479,\n",
       "  0.0020342856954637077,\n",
       "  0.003616507903046592,\n",
       "  0.0056507935985103,\n",
       "  0.00813714278185483,\n",
       "  0.011075555453080185,\n",
       "  0.014466031612186368,\n",
       "  0.01830857125917337,\n",
       "  0.022603174394041196],\n",
       " 'qini_30p': 0.0007192176703881316,\n",
       " 'qini_10p': 0.00013264721151273702}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, (train_index, test_index) in enumerate(fold_gen):\n",
    "    X_train = X.reindex(train_index)\n",
    "    X_test = X.reindex(test_index)\n",
    "    if (dataset != 'lalonde'):\n",
    "        Y = ty.apply(y_assign)\n",
    "        T = ty.apply(t_assign)\n",
    "    Y_train = Y.reindex(train_index)\n",
    "    Y_test = Y.reindex(test_index)\n",
    "    T_train = T.reindex(train_index)\n",
    "    T_test = T.reindex(test_index)\n",
    "    mdl = tma(X_train, Y_train, T_train)\n",
    "    pred = predict_tma(mdl, X_test)\n",
    "    perf = performance(pred['pr_y1_t1'], pred['pr_y1_t0'], Y_test, T_test)\n",
    "    q = qini(perf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n        mdl = tma(X_train, Y_train, T_train)\\n        pred = predict_tma(mdl, X_test)\\n        print(pred)        \\n        # TODO: performance()\\n        # TODO: qini()\\n\\n        ### Variable selection (General wrapper approach) ###\\n\\n        ### Parameter tuning ###\\n\\n#         print(\"Model: {}\\n\".format(model))\\n#         print(\"Tuning space: \\n\")\\n#         for key, val in search_space.items():\\n#             print(\"    \\'{}\\': {}\\n\".format(key, val))\\n#         print(\"Seed: {}\\n\".format(seed))\\n#         print(\"Qini value: mean = {}, std = {}\\n\\n\".format(mean_qini, std_qini))\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "        mdl = tma(X_train, Y_train, T_train)\n",
    "        pred = predict_tma(mdl, X_test)\n",
    "        print(pred)        \n",
    "        # TODO: performance()\n",
    "        # TODO: qini()\n",
    "\n",
    "        ### Variable selection (General wrapper approach) ###\n",
    "\n",
    "        ### Parameter tuning ###\n",
    "\n",
    "#         print(\"Model: {}\\n\".format(model))\n",
    "#         print(\"Tuning space: \\n\")\n",
    "#         for key, val in search_space.items():\n",
    "#             print(\"    '{}': {}\\n\".format(key, val))\n",
    "#         print(\"Seed: {}\\n\".format(seed))\n",
    "#         print(\"Qini value: mean = {}, std = {}\\n\\n\".format(mean_qini, std_qini))\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
